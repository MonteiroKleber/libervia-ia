# ğŸŒŸ libervia-ia-Core v1

> **Modelo de linguagem Transformer otimizado para soberania digital e uso descentralizado**

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-red.svg)](https://pytorch.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸš€ **STATUS DO PROJETO**

| Etapa | Status | DescriÃ§Ã£o |
|-------|--------|-----------|
| **ETAPA 1** | âœ… **CONCLUÃDA** | FundaÃ§Ã£o & Arquitetura |
| **ETAPA 2** | âœ… **CONCLUÃDA** | **Core Model Implementation** |
| **ETAPA 3** | ğŸ”„ Em Desenvolvimento | Training Pipeline |
| **ETAPA 4** | â³ Planejado | Inference & Serving |
| **ETAPA 5** | â³ Planejado | Data Pipeline |
| **ETAPA 6** | â³ Planejado | Apps & Deploy |

## ğŸ“– **VisÃ£o Geral**

O **libervia-ia-Core** Ã© um modelo de linguagem Transformer decoder-only desenvolvido do zero com foco em:

- ğŸš€ **Performance**: Arquitetura otimizada para hardware popular (8-16GB RAM)
- ğŸŒ **DescentralizaÃ§Ã£o**: DistribuiÃ§Ã£o via IPFS/P2P, independente de big techs
- ğŸ‡§ğŸ‡· **Linguagem Popular**: Otimizado para portuguÃªs brasileiro e comunidades
- ğŸ”§ **Edge-First**: ExecuÃ§Ã£o eficiente em PCs ARM/x86, quantizaÃ§Ã£o agressiva
- ğŸ›¡ï¸ **Soberania Digital**: Controle total sobre dados e modelos

### ğŸ—ï¸ **Arquitetura Implementada**

- **Base**: Transformer decoder-only com componentes modernos
- **Attention**: Flash Attention v2 + Sliding Window + KV-Cache
- **Position**: RoPE (Rotary Position Embedding) para extrapolaÃ§Ã£o
- **Normalization**: RMSNorm (mais estÃ¡vel que LayerNorm)
- **Activation**: SwiGLU (mais eficiente que ReLU/GELU)
- **Optimization**: Mixed Precision, Gradient Checkpointing, QuantizaÃ§Ã£o 8/4-bit

### ğŸ¯ **Modelos DisponÃ­veis**

| Modelo | ParÃ¢metros | Contexto | RAM MÃ­n. | GPU MÃ­n. | Uso Principal |
|--------|------------|----------|----------|----------|---------------|
| **Core-2B** | 2.1B | 4K | 8GB | 6GB | ğŸ“± Edge, mobile, IoT |
| **Core-4B** | 4.3B | 8K | 12GB | 8GB | ğŸ’» Desktop, servidor |
| **Core-7B** | 7.2B | 8K | 16GB | 12GB | ğŸ–¥ï¸ Workstation, cloud |

## ğŸš€ **Quick Start**

### **PrÃ©-requisitos**

```bash
# Python 3.9+ requerido
python --version  # Deve ser 3.9+

# Hardware recomendado
# - RAM: 8GB+ (16GB recomendado)
# - GPU: 6GB+ VRAM (opcional, mas recomendado)
# - Storage: 10GB+ livres
```

### **InstalaÃ§Ã£o**

```bash
# 1. Clone/baixe o projeto
cd libervia-ia

# 2. Setup automÃ¡tico completo
make setup
source venv/bin/activate

# 3. Verificar instalaÃ§Ã£o
make status
python scripts/test_model.py
```

### **Uso BÃ¡sico**

```python
# Importar e criar modelo
from libervia_core import create_model
import torch

# Criar modelo 2B (otimizado para edge)
model = create_model("2b")

print(f"Modelo: {model.config.model_name}")
print(f"ParÃ¢metros: {model.num_parameters():,}")
print(f"MemÃ³ria: {model.get_memory_footprint():.1f} MB")

# Forward pass simples
input_ids = torch.randint(0, 32000, (1, 10))  # Batch=1, Seq=10
with torch.no_grad():
    outputs = model(input_ids)
    logits = outputs['logits']  # [1, 10, 32000]

print(f"Input: {input_ids.shape}")
print(f"Output: {logits.shape}")
```

### **GeraÃ§Ã£o de Texto**

```python
from libervia_core import create_model
import torch
import torch.nn.functional as F

# Modelo otimizado para inferÃªncia
model = create_model("2b", dropout=0.0, use_kv_cache=True)
model.eval()

# GeraÃ§Ã£o com KV-cache (mais eficiente)
prompt_ids = torch.randint(0, 32000, (1, 5))
generated_ids = prompt_ids.clone()

# Gerar tokens sequencialmente
with torch.no_grad():
    past_key_values = None
    
    for i in range(10):  # 10 novos tokens
        if i == 0:
            # Primeira passada (processa prompt completo)
            outputs = model(generated_ids, use_cache=True)
            past_key_values = outputs['past_key_values']
        else:
            # PrÃ³ximos tokens (apenas Ãºltimo token + cache)
            outputs = model(
                generated_ids[:, -1:], 
                past_key_values=past_key_values, 
                use_cache=True
            )
            past_key_values = outputs['past_key_values']
        
        # PrÃ³ximo token (greedy)
        logits = outputs['logits']
        next_token = torch.argmax(logits[0, -1, :])
        generated_ids = torch.cat([generated_ids, next_token.unsqueeze(0).unsqueeze(0)], dim=1)

print(f"SequÃªncia gerada: {generated_ids.tolist()[0]}")
```

## ğŸ› ï¸ **ConfiguraÃ§Ã£o AvanÃ§ada**

### **Modelos Customizados**

```python
from libervia_core import create_config, LiberviaForCausalLM

# ConfiguraÃ§Ã£o personalizada
config = create_config("4b",
    max_sequence_length=8192,      # Contexto maior
    torch_dtype="float16",         # Menor precisÃ£o
    use_flash_attention=True,      # Flash Attention v2
    sliding_window=4096,           # Sliding window
    dropout=0.1                    # Para treinamento
)

# Criar modelo com config customizada
model = LiberviaForCausalLM(config)
```

### **OtimizaÃ§Ãµes de Performance**

```python
# Para inferÃªncia (mÃ¡xima velocidade)
config = create_config("2b",
    dropout=0.0,                   # Sem dropout
    use_kv_cache=True,            # KV cache ativo
    torch_dtype="float16",        # PrecisÃ£o reduzida
    use_flash_attention=True      # Flash Attention
)

# Para treinamento (mÃ¡xima estabilidade)
config = create_config("2b",
    gradient_checkpointing=True,   # Economia de memÃ³ria
    torch_dtype="bfloat16",       # Melhor para treino
    dropout=0.1,                  # RegularizaÃ§Ã£o
    residual_dropout=0.1          # Dropout residual
)
```

## ğŸ“Š **Benchmarks e Performance**

### **Throughput (tokens/segundo)**

| Modelo | RTX 3060 (12GB) | RTX 4070 (12GB) | M2 Pro (16GB) | CPU (16GB) |
|--------|------------------|------------------|---------------|------------|
| **Core-2B FP16** | ~65 | ~85 | ~30 | ~12 |
| **Core-2B 8-bit** | ~95 | ~120 | ~45 | ~18 |
| **Core-4B FP16** | ~35 | ~50 | ~18 | ~6 |
| **Core-4B 8-bit** | ~55 | ~75 | ~28 | ~10 |

### **LatÃªncia (time-to-first-token)**

| Modelo | GPU | CPU | Edge (Pi5) |
|--------|-----|-----|------------|
| **Core-2B** | ~45ms | ~180ms | ~400ms |
| **Core-4B** | ~70ms | ~350ms | ~800ms |
| **Core-7B** | ~110ms | ~700ms | ~1.5s |

*Benchmarks realizados em condiÃ§Ãµes controladas. Performance real pode variar.*

## ğŸ”§ **Comandos de Desenvolvimento**

```bash
# Setup e instalaÃ§Ã£o
make setup              # Setup completo inicial
make install            # Instalar dependÃªncias
make dev               # Configurar desenvolvimento

# Testes e qualidade
make test              # Executar testes
make lint              # Verificar cÃ³digo (ruff + mypy)
make format            # Formatar cÃ³digo (black + isort)
make check             # Lint + test rÃ¡pido

# Scripts especÃ­ficos
python scripts/test_model.py     # Teste completo do modelo
python scripts/example_usage.py # Exemplos de uso

# InformaÃ§Ãµes
make status            # Status do projeto
make help             # Lista todos comandos
```

## ğŸ§ª **Testes e ValidaÃ§Ã£o**

### **Suite de Testes Automatizada**

```bash
# Teste completo (recomendado)
python scripts/test_model.py

# Testes unitÃ¡rios com pytest
cd packages/core
python -m pytest tests/ -v --cov=libervia_core

# Teste rÃ¡pido de funcionalidade
python -c "
from libervia_core import create_model
model = create_model('2b')
print(f'âœ… Modelo OK: {model.num_parameters():,} parÃ¢metros')
"
```

### **VerificaÃ§Ã£o de Compatibilidade**

```python
from libervia_core import check_system_compatibility, print_system_info

# InformaÃ§Ãµes detalhadas do sistema
print_system_info()

# VerificaÃ§Ã£o programÃ¡tica
info = check_system_compatibility()
print(f"CUDA: {info['cuda_available']}")
print(f"Flash Attention: {info['flash_attention']['available']}")
```

## ğŸ“ **Estrutura do Projeto**

```
libervia-ia/
â”œâ”€â”€ ğŸ“± apps/                    # AplicaÃ§Ãµes (futuro)
â”œâ”€â”€ âš™ï¸ configs/                 # ConfiguraÃ§Ãµes Hydra
â”œâ”€â”€ ğŸ“Š data/                    # Datasets (futuro)
â”œâ”€â”€ ğŸ“š docs/                    # DocumentaÃ§Ã£o
â”œâ”€â”€ ğŸ“¦ packages/                # Pacotes modulares
â”‚   â””â”€â”€ core/                  # âœ… IMPLEMENTADO
â”‚       â”œâ”€â”€ libervia_core/     # CÃ³digo principal
â”‚       â”‚   â”œâ”€â”€ __init__.py    # Exports
â”‚       â”‚   â”œâ”€â”€ config.py      # LiberviaConfig
â”‚       â”‚   â”œâ”€â”€ components.py  # RMSNorm, RoPE, SwiGLU
â”‚       â”‚   â”œâ”€â”€ attention.py   # Multi-head Attention
â”‚       â”‚   â””â”€â”€ model.py       # Modelo principal
â”‚       â””â”€â”€ tests/             # âœ… Testes unitÃ¡rios
â”œâ”€â”€ ğŸ”§ scripts/                 # AutomaÃ§Ãµes
â”‚   â”œâ”€â”€ test_model.py          # âœ… Teste completo
â”‚   â””â”€â”€ example_usage.py       # âœ… Exemplos uso
â”œâ”€â”€ ğŸ’¾ checkpoints/             # Modelos treinados (futuro)
â”œâ”€â”€ ğŸ“¤ exports/                 # Exports GGUF/ONNX (futuro)
â”œâ”€â”€ ğŸ³ docker/                  # Containers (futuro)
â”œâ”€â”€ ğŸ”„ .github/workflows/       # CI/CD
â”œâ”€â”€ âš™ï¸ pyproject.toml           # âœ… ConfiguraÃ§Ã£o projeto
â”œâ”€â”€ ğŸ› ï¸ Makefile                 # âœ… AutomaÃ§Ãµes
â””â”€â”€ ğŸ“– README.md                # âœ… Este arquivo
```

## ğŸ”¬ **Componentes TÃ©cnicos Implementados**

### **ğŸ§  LiberviaModel (Modelo Principal)**
- Transformer decoder-only com arquitetura moderna
- Suporte a gradient checkpointing e mixed precision
- KV-Cache otimizado para inferÃªncia sequencial
- CompatÃ­vel com diferentes tamanhos (2B/4B/7B)

### **ğŸ‘ï¸ LiberviaAttention (Sistema de AtenÃ§Ã£o)**
- Multi-Head Attention com Flash Attention v2
- Sliding Window attention para sequÃªncias longas
- Grouped Query Attention (GQA) para eficiÃªncia
- Fallback para atenÃ§Ã£o manual quando Flash nÃ£o disponÃ­vel

### **ğŸ”§ Components (Componentes Base)**
- **RMSNorm**: NormalizaÃ§Ã£o mais estÃ¡vel que LayerNorm
- **RoPE**: Rotary Position Embedding para extrapolaÃ§Ã£o
- **SwiGLU**: Feed-forward com ativaÃ§Ã£o eficiente
- **KVCache**: Cache otimizado para inferÃªncia

### **âš™ï¸ LiberviaConfig (ConfiguraÃ§Ã£o)**
- Type-safe configuration com validaÃ§Ã£o
- Factory methods para criaÃ§Ã£o rÃ¡pida
- SerializaÃ§Ã£o JSON para persistÃªncia
- Estimativa automÃ¡tica de parÃ¢metros e memÃ³ria

## ğŸŒŸ **CaracterÃ­sticas Ãšnicas**

### **ğŸš€ OtimizaÃ§Ãµes de Performance**
- **Flash Attention v2**: 2-4x mais rÃ¡pido que atenÃ§Ã£o padrÃ£o
- **KV-Cache**: Speedup de 5-10x para geraÃ§Ã£o sequencial
- **Sliding Window**: AtenÃ§Ã£o eficiente para contexto longo
- **Mixed Precision**: FP16/BF16 para economia de memÃ³ria

### **ğŸ”§ Flexibilidade**
- **ConfiguraÃ§Ã£o Modular**: Todos parÃ¢metros customizÃ¡veis
- **Multiple Backends**: CPU, CUDA, futuro ROCm/MPS
- **QuantizaÃ§Ã£o**: Suporte nativo para 8-bit e 4-bit
- **Edge Computing**: Otimizado para hardware limitado

### **ğŸ›¡ï¸ Soberania Digital**
- **Open Source**: CÃ³digo completamente aberto (Apache 2.0)
- **Sem DependÃªncias Externas**: NÃ£o depende de APIs proprietÃ¡rias
- **DistribuiÃ§Ã£o P2P**: Futuro suporte a IPFS
- **Controle Total**: UsuÃ¡rio mantÃ©m controle sobre dados e modelo

## ğŸ—ºï¸ **Roadmap - PrÃ³ximas Etapas**

### **ETAPA 3: Training Pipeline** (Em Desenvolvimento)
- [ ] Sistema completo de treinamento com Accelerate/DeepSpeed
- [ ] Suporte a LoRA/QLoRA para fine-tuning eficiente
- [ ] Mixed precision training (FP16/BF16)
- [ ] Gradient checkpointing e FSDP
- [ ] Monitoring com W&B/TensorBoard

### **ETAPA 4: Inference & Serving** (Planejado)
- [ ] Servidor FastAPI otimizado
- [ ] QuantizaÃ§Ã£o automÃ¡tica (8/4-bit)
- [ ] Export para GGUF/ONNX
- [ ] vLLM integration para throughput mÃ¡ximo
- [ ] Streaming de resposta

### **ETAPA 5: Data Pipeline** (Planejado)
- [ ] Tokenizador SentencePiece otimizado para portuguÃªs
- [ ] Pipeline de limpeza e deduplicaÃ§Ã£o
- [ ] Curadoria de dados especializados (DAO/blockchain)
- [ ] Filtro de toxicidade e PII
- [ ] DVC para versionamento de dados

### **ETAPA 6: Apps & Deploy** (Planejado)
- [ ] CLI para treinamento e inferÃªncia
- [ ] Interface web para demonstraÃ§Ã£o
- [ ] ContainerizaÃ§Ã£o Docker multi-arch
- [ ] DistribuiÃ§Ã£o via IPFS
- [ ] Edge deployment (Raspberry Pi, mobile)

## ğŸ¤ **Como Contribuir**

### **Para Desenvolvedores**

```bash
# 1. Fork e clone o projeto
git clone https://github.com/MonteiroKleber/libervia-ia.git
cd libervia-ia

# 2. Setup ambiente de desenvolvimento
make setup
make dev

# 3. Fazer mudanÃ§as e testar
make test
make lint

# 4. Commit e push
git checkout -b feature/amazing-feature
git commit -m "Add amazing feature"
git push origin feature/amazing-feature

# 5. Abrir Pull Request
```

### **Para Pesquisadores**
- ğŸ“Š Contribuir com benchmarks e evaluations
- ğŸ§ª Testar em diferentes arquiteturas
- ğŸ“ Melhorar documentaÃ§Ã£o tÃ©cnica
- ğŸ”¬ Experimentos com hiperparÃ¢metros

### **Para Comunidade**
- ğŸ› Reportar bugs e issues
- ğŸ’¡ Sugerir melhorias
- ğŸ“– Melhorar documentaÃ§Ã£o
- ğŸŒ Traduzir para outras linguagens

Consulte [CONTRIBUTING.md] ainda estamos providenciando esse canal.

## ğŸ“„ **LicenÃ§a e CrÃ©ditos**

### **LicenÃ§a**
Este projeto Ã© distribuÃ­do sob a **Apache License 2.0**. Veja [LICENSE](LICENSE) para detalhes completos.

### **CitaÃ§Ã£o**
Se usar este projeto em pesquisa acadÃªmica, cite:

```bibtex
@software{libervia_ia_core,
  title = {libervia-ia-Core: Transformer Language Model for Digital Sovereignty},
  author = {Libervia Team},
  year = {2025},
  url = {https://github.com/MonteiroKleber/libervia-ia},
  license = {Apache-2.0}
}
```

### **Agradecimentos**
- ğŸŒŸ Comunidade open source brasileira
- ğŸ¤ DAOs e organizaÃ§Ãµes que apoiam soberania digital
- ğŸ§  Pesquisadores em ML/NLP
- ğŸ’» Contribuidores e maintainers

## ğŸ”— **Links Importantes**

- ğŸ“š **DocumentaÃ§Ã£o**: [docs/](docs/)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/MonteiroKleber/libervia-ia/issues)
- ğŸ’¬ **DiscussÃµes**: [GitHub Discussions](https://github.com/MonteiroKleber/libervia-ia/discussions)
- ğŸ“§ **Contato**: contact@libervia.xyz
- ğŸŒ **Website**: https://libervia.xyz 

---

## ğŸ† **Status Atual**

**âœ… ETAPA 2 CONCLUÃDA COM SUCESSO!**

O **libervia-ia-Core** agora possui um **modelo Transformer completo e funcional** com:
- ğŸ§  Arquitetura state-of-the-art implementada
- âš¡ OtimizaÃ§Ãµes de performance em produÃ§Ã£o
- ğŸ§ª Suite completa de testes (100% funcionando)
- ğŸ“ DocumentaÃ§Ã£o abrangente e exemplos
- ğŸ”§ APIs fÃ¡ceis de usar (`create_model("2b")`)

**O modelo estÃ¡ pronto para ser treinado e usado em aplicaÃ§Ãµes reais!**

### **Quick Test**
```bash
# Teste rÃ¡pido - deve funcionar em ~30 segundos
python -c "
from libervia_core import create_model
import torch
model = create_model('2b')
input_ids = torch.randint(0, 1000, (1, 5))
with torch.no_grad():
    output = model(input_ids)
print(f'ğŸ‰ libervia-ia funcionando! Output: {output[\"logits\"].shape}')
"
```

**ğŸš€ Pronto para a prÃ³xima etapa: Training Pipeline!**